# âœ… ì „ì´í•™ìŠµì´ë€?
- **ì „ì´í•™ìŠµ**(Transfer Learning)ì€ í•œ ë¬¸ì œ(domain)ì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì˜ ì§€ì‹ì´ë‚˜ íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ë¥¸ ë¬¸ì œë¡œ ì „ì´í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.
- ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì™€ ì—°ì‚°ì„ í•„ìš”ë¡œ í•˜ì§€ë§Œ, ì „ì´í•™ìŠµì„ ì´ìš©í•˜ë©´ **ì ì€ ë°ì´í„°ë¡œë„ íš¨ê³¼ì ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì¼** ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì£¼ìš” ê°œë…

- **ì†ŒìŠ¤ ë„ë©”ì¸(Source Domain)**: ê¸°ì¡´ì— í•™ìŠµì´ ì´ë£¨ì–´ì¡Œë˜ ë°ì´í„°ì™€ ê³¼ì œ
- **íƒ€ê¹ƒ ë„ë©”ì¸(Target Domain)**: ì§€ì‹ì„ ì´ì „ë°›ì•„ ì ìš©í•  ìƒˆë¡œìš´ ë°ì´í„°ì™€ ê³¼ì œ
- **íŒŒì¸íŠœë‹(Fine-tuning)**: ê¸°ì¡´ ëª¨ë¸ì˜ ì¼ë¶€ í˜¹ì€ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ìƒˆë¡œìš´ ë°ì´í„°ì— ë§ê²Œ ì¡°ê¸ˆì”© ì¡°ì •í•˜ëŠ” ê³¼ì •
- **Feature Extraction**: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì—ì„œ íŠ¹ì§•ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œì— ì‚¬ìš©

### 2ï¸âƒ£ ì „ì´í•™ìŠµì˜ ë°©ì‹

| ë°©ì‹            | ì„¤ëª…                                                                      |
|-----------------|---------------------------------------------------------------------------|
| Feature-based   | ê¸°ì¡´ ëª¨ë¸ì˜ feature extractorë§Œ ì‚¬ìš©, ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° ë¶€ë¶„ë§Œ ìƒˆë¡œ í•™ìŠµ          |
| Fine-tuning     | ì „ì²´ ë˜ëŠ” ì¼ë¶€ ë ˆì´ì–´ë¥¼ íƒ€ê¹ƒ ë„ë©”ì¸ ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ                      |
| Multi-task      | ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— í•™ìŠµí•˜ë©°, ê³µìœ ëœ ì§€ì‹ì„ ì„œë¡œ ë‹¤ë¥¸ ì‘ì—…ì— í™œìš©               |
| Zero-shot/One-shot | ì†ŒëŸ‰ ë˜ëŠ” ì „í˜€ ì—†ëŠ” ë ˆì´ë¸” ë°ì´í„°ë¡œ íƒ€ê¹ƒ ë„ë©”ì¸ì„ ì²˜ë¦¬                     |

### 3ï¸âƒ£ ì „ì´í•™ìŠµì˜ ëŒ€í‘œì  í™œìš© ì˜ˆì‹œ

- **ì»´í“¨í„° ë¹„ì „**: ImageNet ë“± ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ CNN ëª¨ë¸ì„, ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°(ì˜ˆ: ì˜ë£Œ ì´ë¯¸ì§€)ì— íŒŒì¸íŠœë‹
- **ìì—°ì–´ ì²˜ë¦¬**: BERT, GPT ë“± ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ëª¨ë¸ì„, ì§ˆì˜ì‘ë‹µ ë˜ëŠ” ê°ì •ë¶„ì„ ë“± íŠ¹ì • ì‘ì—…ì— ì ìš©
- **ìŒì„± ì¸ì‹**: ëŒ€ê·œëª¨ ìŒì„± ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ê°œë³„ ì‚¬ìš©ì ìŒì„± ì¸ì‹ì— ì ìš©

### 4ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì¥ì ê³¼ í•œê³„

- **ì¥ì **
  - ì ì€ ë°ì´í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥
  - í•™ìŠµ ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤ ì ˆê°
  - ì†Œê·œëª¨ ë°ì´í„°ì…‹ì— ê°•ì 

- **í•œê³„**
  - ì†ŒìŠ¤ì™€ íƒ€ê¹ƒ ë„ë©”ì¸ ì‚¬ì´ ì°¨ì´ê°€ í¬ë©´ íš¨ê³¼â†“
  - ë¹„ì •ìƒì ì¸ ì „ì´(negative transfer) ê°€ëŠ¥ì„±
  - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ì–´ë ¤ì›€

### 5ï¸âƒ£ ì „ì´í•™ìŠµì˜ ëŒ€í‘œ ëª¨ë¸

- **ë¹„ì „**: ResNet, VGG, Inception ë“±
- **ìì—°ì–´ ì²˜ë¦¬**: BERT, GPT, RoBERTa, T5 ë“±

### 6ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì‹¤ìŠµ ì˜ˆì‹œ (PyTorch ê¸°ì¤€)

```
python
import torch
import torchvision.models as models

# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = models.resnet50(pretrained=True)

# ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´ êµì²´ (ì˜ˆ: í´ë˜ìŠ¤ 2ê°œì¸ ê²½ìš°)
import torch.nn as nn
model.fc = nn.Linear(model.fc.in_features, 2)

# íŒŒì¸íŠœë‹
for param in model.parameters():
    param.requires_grad = False  # feature extraction
for param in model.fc.parameters():
    param.requires_grad = True

# ì´í›„ í•™ìŠµ ë£¨í”„ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
```

### 7ï¸âƒ£ ëŒ€í‘œ í”„ë ˆì„ì›Œí¬ & ì‹¤ì „ ì½”ë“œ

- **PyTorch**
```
python
import torch
import torchvision.models as models
import torch.nn as nn

model = models.resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # ë¶„ë¥˜ê¸° êµì²´

for param in model.parameters():
    param.requires_grad = False  # Feature extraction
for param in model.fc.parameters():
    param.requires_grad = True   # Classifierë§Œ í•™ìŠµ
```

- **TensorFlow/Keras**
  
```
python
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))
base_model.trainable = False  # Feature extractorë§Œ ì‚¬ìš©

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(2, activation='softmax')
])
```
---

## âœï¸ ì‚¬ì „ í•™ìŠµëœ ConvNetì„ ì´ìš©í•œ ì „ì´ í•™ìŠµ
### ë°ì´í„° ì „ì²˜ë¦¬
#### ë°ì´í„° ë‹¤ìš´ë¡œë“œ
- ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ìˆ˜ì²œ ê°œì˜ ê³ ì–‘ì´ì™€ ê°œì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì´ë¯¸ì§€ê°€ í¬í•¨ëœ zip íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¶”ì¶œì€ ë‹¤ìŒ `tf.keras.utils.image_dataset_from_directory` ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° ê²€ì¦ì„ ìœ„í•œ `tf.data.Dataset`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                            shuffle=True,
                                                            batch_size=BATCH_SIZE,
                                                            image_size=IMG_SIZE)
```

```
validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,
                                                                 shuffle=True,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE)
```
- í›ˆë ¨ìš© ë°ì´í„°ì…‹ì—ì„œ ì²˜ìŒ ë‘ ê°œì˜ ì´ë¯¸ì§€ ë° ë ˆì´ë¸”ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:
```
class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```
https://www.tensorflow.org/static/tutorials/images/transfer_learning_files/output_K5BeQyKThC_Y_0.png?hl=ko<img width="793" height="812" alt="image" src="https://github.com/user-attachments/assets/eed17668-b450-49b8-b126-261c3c624ec1" />


---

### 8ï¸âƒ£ ì „ì´í•™ìŠµì˜ ìµœì‹  íŠ¸ë Œë“œ ë° ê³ ê¸‰ ê¸°ë²•

- **ë„ë©”ì¸ ì ì‘(Domain Adaptation):** ë°ì´í„° ë¶„í¬ê°€ ë‹¤ë¥¸ ì†ŒìŠ¤ì™€ íƒ€ê¹ƒ ì‚¬ì´ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ê¸°ìˆ 
- **ë©€í‹°íƒœìŠ¤í¬ ëŸ¬ë‹(Multi-task Learning):** ì—¬ëŸ¬ ì‘ì—…ì—ì„œ ê³µí†µ íŠ¹ì„± ì¶”ì¶œí•´ ì¼ë°˜í™” ëŠ¥ë ¥ ê°•í™”
- **ì œë¡œìƒ·/í“¨ìƒ· ëŸ¬ë‹:** ë°ì´í„° ë¶€ì¡± ìƒí™©ì—ì„œì˜ ì¼ë°˜í™”(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë“±)
- **ì—°ì†ì  í•™ìŠµ(Lifelong/Continual Learning):** ì—¬ëŸ¬ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµí•˜ë©´ì„œ ê³¼ê±° ê²½í—˜ì„ ë³´ì¡´í•˜ëŠ” ì—°êµ¬
- **í˜ë”ë ˆì´í‹°ë“œ ëŸ¬ë‹:** ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë¶„ì‚°í˜•ìœ¼ë¡œ í•™ìŠµ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œì™€ ì•ˆì „ ê³ ë ¤


### 9ï¸âƒ£ ì „ì´í•™ìŠµ ì‚°ì—… ì‘ìš©ì‚¬ë¡€

- **ì˜ë£Œ:** ì•” ì§„ë‹¨, ë³‘ë³€ íƒì§€ ë“± ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„
- **ê¸ˆìœµ:** ì‹ ìš©í‰ê°€, ì‚¬ê¸° íƒì§€
- **ì œì¡°Â·ì‚°ì—…:** ë¶ˆëŸ‰ ê°ì§€, ì„¤ë¹„ ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜
- **ììœ¨ì£¼í–‰:** ì°¨ëŸ‰ íƒ‘ì¬ ì„¼ì„œì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ë³„ë¡œ íŠ¹í™”ëœ í•™ìŠµ

### ğŸ”Ÿ ì°¸ê³ ìë£Œ (ì¶”ì²œ ë§í¬ ë° ë…¼ë¬¸)

- "Transfer Learning â€” Deep Learning Glossary", DeepAI.
- "A comprehensive introduction to transfer learning", Towards Data Science.
- "Transfer Learning in NLP", Google Developers.
- Papers with Code: Transfer Learning ë¶„ì•¼ ìµœì‹  ì½”ë“œÂ·ë…¼ë¬¸
- "A Survey on Transfer Learning": ì „ì´í•™ìŠµ ìµœì‹  ë™í–¥/ë¦¬ë·°ë…¼ë¬¸



