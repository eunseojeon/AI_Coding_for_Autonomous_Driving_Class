# âœ… ì „ì´í•™ìŠµì´ë€?
- **ì „ì´í•™ìŠµ**(Transfer Learning)ì€ í•œ ë¬¸ì œ(domain)ì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì˜ ì§€ì‹ì´ë‚˜ íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ë¥¸ ë¬¸ì œë¡œ ì „ì´í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.
- ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì™€ ì—°ì‚°ì„ í•„ìš”ë¡œ í•˜ì§€ë§Œ, ì „ì´í•™ìŠµì„ ì´ìš©í•˜ë©´ **ì ì€ ë°ì´í„°ë¡œë„ íš¨ê³¼ì ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì¼** ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="793" height="790" alt="image" src="https://github.com/user-attachments/assets/95e451c1-63d8-4857-aaea-c285fc9c79a5" />


### 1ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì£¼ìš” ê°œë…

- **ì†ŒìŠ¤ ë„ë©”ì¸(Source Domain)**: ê¸°ì¡´ì— í•™ìŠµì´ ì´ë£¨ì–´ì¡Œë˜ ë°ì´í„°ì™€ ê³¼ì œ
- **íƒ€ê¹ƒ ë„ë©”ì¸(Target Domain)**: ì§€ì‹ì„ ì´ì „ë°›ì•„ ì ìš©í•  ìƒˆë¡œìš´ ë°ì´í„°ì™€ ê³¼ì œ
- **íŒŒì¸íŠœë‹(Fine-tuning)**: ê¸°ì¡´ ëª¨ë¸ì˜ ì¼ë¶€ í˜¹ì€ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ìƒˆë¡œìš´ ë°ì´í„°ì— ë§ê²Œ ì¡°ê¸ˆì”© ì¡°ì •í•˜ëŠ” ê³¼ì •
- **Feature Extraction**: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì—ì„œ íŠ¹ì§•ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œì— ì‚¬ìš©

### 2ï¸âƒ£ ì „ì´í•™ìŠµì˜ ë°©ì‹

| ë°©ì‹            | ì„¤ëª…                                                                      |
|-----------------|---------------------------------------------------------------------------|
| Feature-based   | ê¸°ì¡´ ëª¨ë¸ì˜ feature extractorë§Œ ì‚¬ìš©, ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° ë¶€ë¶„ë§Œ ìƒˆë¡œ í•™ìŠµ          |
| Fine-tuning     | ì „ì²´ ë˜ëŠ” ì¼ë¶€ ë ˆì´ì–´ë¥¼ íƒ€ê¹ƒ ë„ë©”ì¸ ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ                      |
| Multi-task      | ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— í•™ìŠµí•˜ë©°, ê³µìœ ëœ ì§€ì‹ì„ ì„œë¡œ ë‹¤ë¥¸ ì‘ì—…ì— í™œìš©               |
| Zero-shot/One-shot | ì†ŒëŸ‰ ë˜ëŠ” ì „í˜€ ì—†ëŠ” ë ˆì´ë¸” ë°ì´í„°ë¡œ íƒ€ê¹ƒ ë„ë©”ì¸ì„ ì²˜ë¦¬                     |

### 3ï¸âƒ£ ì „ì´í•™ìŠµì˜ ëŒ€í‘œì  í™œìš© ì˜ˆì‹œ

- **ì»´í“¨í„° ë¹„ì „**: ImageNet ë“± ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ CNN ëª¨ë¸ì„, ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°(ì˜ˆ: ì˜ë£Œ ì´ë¯¸ì§€)ì— íŒŒì¸íŠœë‹
- **ìì—°ì–´ ì²˜ë¦¬**: BERT, GPT ë“± ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ëª¨ë¸ì„, ì§ˆì˜ì‘ë‹µ ë˜ëŠ” ê°ì •ë¶„ì„ ë“± íŠ¹ì • ì‘ì—…ì— ì ìš©
- **ìŒì„± ì¸ì‹**: ëŒ€ê·œëª¨ ìŒì„± ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ê°œë³„ ì‚¬ìš©ì ìŒì„± ì¸ì‹ì— ì ìš©

### ì „ì´ í•™ìŠµì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸

- ì „ì´ í•™ìŠµì˜ ì¤‘ì‹¬ì—ëŠ” ë”¥ëŸ¬ë‹ ì—°êµ¬ìë“¤ì´ ìˆ˜ë°±ë§Œ ê°œì˜ ìƒ˜í”Œ ë°ì´í„° ì ìœ¼ë¡œ í›ˆë ¨ì‹œí‚¨ ì‚¬ì „ í›ˆë ¨ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.
- ë§ì€ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì´ ì¡´ì¬í•˜ë©° ê°ê°ì˜ ëª¨ë¸ì—ëŠ” ê³ ë ¤í•´ì•¼ í•  ë‹¤ìŒê³¼ ê°™ì€ ì¥ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.
- - **ì˜ˆì¸¡ ì†ë„: ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ìƒˆ ì…ë ¥ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ê°€?** ì˜ˆì¸¡ ì†ë„ëŠ” í•˜ë“œì›¨ì–´ ë° ë°°ì¹˜ í¬ê¸°ì™€ ê°™ì€ ì¸ìì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ì™€ í¬ê¸°ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
- - **í¬ê¸°: ëª¨ë¸ì— í•„ìš”í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì–´ëŠ ì •ë„ì¸ê°€?** ëª¨ë¸ í¬ê¸°ì˜ ì¤‘ìš”ì„±ì€ ëª¨ë¸ì„ ì–´ë””ë¡œ ê·¸ë¦¬ê³  ì–´ë–»ê²Œ ë°°í¬í•˜ë ¤ëŠ”ì§€ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ì˜ˆë¡œ ëª¨ë¸ì„ ì„ë² ë””ë“œ í•˜ë“œì›¨ì–´ ë˜ëŠ” ë°ìŠ¤í¬íƒ‘ì—ì„œ ì‹¤í–‰í•  ê²ƒì¸ì§€ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ê°€ ì œì•½ëœ íƒ€ê²Ÿì— ë°°í¬í•˜ëŠ” ê²½ìš°ì—ëŠ” ì‹ ê²½ë§ì˜ í¬ê¸°ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
- - **ì •í™•ë„: ì¬í›ˆë ¨í•˜ê¸° ì „ì˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ ì¢‹ì€ê°€?** ImageNet ë°ì´í„°ì…‹ì— ëŒ€í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì€ ìƒˆë¡œìš´ ìœ ì‚¬ ì‘ì—…ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ImageNetì—ì„œ ì •í™•ë„ ì ìˆ˜ê°€ ë‚®ë‹¤ê³  í•´ì„œ ëª¨ë¸ì´ ëª¨ë“  ì‘ì—…ì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.
 
<img width="1128" height="732" alt="image" src="https://github.com/user-attachments/assets/639df41d-e1c0-4c59-9c70-0ebd5ee75d37" />


### 4ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì¥ì ê³¼ í•œê³„

- **ì¥ì **
  - ì ì€ ë°ì´í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥
  - í•™ìŠµ ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤ ì ˆê°
  - ì†Œê·œëª¨ ë°ì´í„°ì…‹ì— ê°•ì 

- **í•œê³„**
  - ì†ŒìŠ¤ì™€ íƒ€ê¹ƒ ë„ë©”ì¸ ì‚¬ì´ ì°¨ì´ê°€ í¬ë©´ íš¨ê³¼â†“
  - ë¹„ì •ìƒì ì¸ ì „ì´(negative transfer) ê°€ëŠ¥ì„±
  - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ì–´ë ¤ì›€

### 5ï¸âƒ£ ì „ì´í•™ìŠµì˜ ëŒ€í‘œ ëª¨ë¸

- **ë¹„ì „**: ResNet, VGG, Inception ë“±
- **ìì—°ì–´ ì²˜ë¦¬**: BERT, GPT, RoBERTa, T5 ë“±

### 6ï¸âƒ£ ì „ì´í•™ìŠµì˜ ì‹¤ìŠµ ì˜ˆì‹œ (PyTorch ê¸°ì¤€)

```
python
import torch
import torchvision.models as models

# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = models.resnet50(pretrained=True)

# ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´ êµì²´ (ì˜ˆ: í´ë˜ìŠ¤ 2ê°œì¸ ê²½ìš°)
import torch.nn as nn
model.fc = nn.Linear(model.fc.in_features, 2)

# íŒŒì¸íŠœë‹
for param in model.parameters():
    param.requires_grad = False  # feature extraction
for param in model.fc.parameters():
    param.requires_grad = True

# ì´í›„ í•™ìŠµ ë£¨í”„ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
```

### 7ï¸âƒ£ ëŒ€í‘œ í”„ë ˆì„ì›Œí¬ & ì‹¤ì „ ì½”ë“œ

- **PyTorch**
```
python
import torch
import torchvision.models as models
import torch.nn as nn

model = models.resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # ë¶„ë¥˜ê¸° êµì²´

for param in model.parameters():
    param.requires_grad = False  # Feature extraction
for param in model.fc.parameters():
    param.requires_grad = True   # Classifierë§Œ í•™ìŠµ
```

- **TensorFlow/Keras**
  
```
python
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))
base_model.trainable = False  # Feature extractorë§Œ ì‚¬ìš©

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(2, activation='softmax')
])
```
---

## âœï¸ ì‚¬ì „ í•™ìŠµëœ ConvNetì„ ì´ìš©í•œ ì „ì´ í•™ìŠµ
### ë°ì´í„° ì „ì²˜ë¦¬
#### ë°ì´í„° ë‹¤ìš´ë¡œë“œ
- ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ìˆ˜ì²œ ê°œì˜ ê³ ì–‘ì´ì™€ ê°œì˜ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì´ë¯¸ì§€ê°€ í¬í•¨ëœ zip íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¶”ì¶œì€ ë‹¤ìŒ `tf.keras.utils.image_dataset_from_directory` ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° ê²€ì¦ì„ ìœ„í•œ `tf.data.Dataset`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                            shuffle=True,
                                                            batch_size=BATCH_SIZE,
                                                            image_size=IMG_SIZE)
```

```
validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,
                                                                 shuffle=True,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE)
```
- í›ˆë ¨ìš© ë°ì´í„°ì…‹ì—ì„œ ì²˜ìŒ ë‘ ê°œì˜ ì´ë¯¸ì§€ ë° ë ˆì´ë¸”ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:
```
class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```
<img width="793" height="812" alt="image" src="https://github.com/user-attachments/assets/eed17668-b450-49b8-b126-261c3c624ec1" />

- ì›ë³¸ ë°ì´í„°ì„¸íŠ¸ì—ëŠ” í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- `tf.data.experimental.cardinality`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ì„¸íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ë°°ì¹˜ ìˆ˜ë¥¼ í™•ì¸í•œ ë‹¤ìŒ ê·¸ ì¤‘ 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤.
```
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))
print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))
```

#### ì„±ëŠ¥ì„ ë†’ì´ë„ë¡ ë°ì´í„°ì„¸íŠ¸ êµ¬ì„±í•˜ê¸°
- ë²„í¼ë§ëœ í”„ë¦¬í˜ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ I/O ì°¨ë‹¨ ì—†ì´ ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
```
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```
#### ë°ì´í„° ì¦ê°• ì‚¬ìš©
- í° ì´ë¯¸ì§€ ë°ì´í„°ì„¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°, íšŒì „ ë° ìˆ˜í‰ ë’¤ì§‘ê¸°ì™€ ê°™ì´ í›ˆë ¨ ì´ë¯¸ì§€ì— ë¬´ì‘ìœ„ì´ì§€ë§Œ ì‚¬ì‹¤ì ì¸ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ìƒ˜í”Œ ë‹¤ì–‘ì„±ì„ ì¸ìœ„ì ìœ¼ë¡œ ë„ì…í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì´ê²ƒì€ ëª¨ë¸ì„ í›ˆë ¨ ë°ì´í„°ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì— ë…¸ì¶œì‹œí‚¤ê³  ê³¼ëŒ€ì í•©ì„ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

```
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('horizontal'),
  tf.keras.layers.RandomRotation(0.2),
])
```
- ì°¸ê³ : `model.fit`ì„ í˜¸ì¶œí•  ë•Œ í›ˆë ¨ ì¤‘ì—ë§Œ ì´ëŸ¬í•œ ë ˆì´ì–´ê°€ í™œì„±í™”ë©ë‹ˆë‹¤.
- `model.evaulate` ë˜ëŠ” `model.fit`ì˜ ì¶”ë¡  ëª¨ë“œì—ì„œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.
- ê°™ì€ ì´ë¯¸ì§€ì— ì´ ë ˆì´ì–´ë¥¼ ë°˜ë³µí•´ì„œ ì ìš©í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.
```
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```

<img width="793" height="790" alt="image" src="https://github.com/user-attachments/assets/3e55046b-05b6-4700-b9ae-cfd83c18adea" />


---

### 8ï¸âƒ£ ì „ì´í•™ìŠµì˜ ìµœì‹  íŠ¸ë Œë“œ ë° ê³ ê¸‰ ê¸°ë²•

- **ë„ë©”ì¸ ì ì‘(Domain Adaptation):** ë°ì´í„° ë¶„í¬ê°€ ë‹¤ë¥¸ ì†ŒìŠ¤ì™€ íƒ€ê¹ƒ ì‚¬ì´ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ê¸°ìˆ 
- **ë©€í‹°íƒœìŠ¤í¬ ëŸ¬ë‹(Multi-task Learning):** ì—¬ëŸ¬ ì‘ì—…ì—ì„œ ê³µí†µ íŠ¹ì„± ì¶”ì¶œí•´ ì¼ë°˜í™” ëŠ¥ë ¥ ê°•í™”
- **ì œë¡œìƒ·/í“¨ìƒ· ëŸ¬ë‹:** ë°ì´í„° ë¶€ì¡± ìƒí™©ì—ì„œì˜ ì¼ë°˜í™”(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë“±)
- **ì—°ì†ì  í•™ìŠµ(Lifelong/Continual Learning):** ì—¬ëŸ¬ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµí•˜ë©´ì„œ ê³¼ê±° ê²½í—˜ì„ ë³´ì¡´í•˜ëŠ” ì—°êµ¬
- **í˜ë”ë ˆì´í‹°ë“œ ëŸ¬ë‹:** ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë¶„ì‚°í˜•ìœ¼ë¡œ í•™ìŠµ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œì™€ ì•ˆì „ ê³ ë ¤


### 9ï¸âƒ£ ì „ì´í•™ìŠµ ì‚°ì—… ì‘ìš©ì‚¬ë¡€

- **ì˜ë£Œ:** ì•” ì§„ë‹¨, ë³‘ë³€ íƒì§€ ë“± ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„
- **ê¸ˆìœµ:** ì‹ ìš©í‰ê°€, ì‚¬ê¸° íƒì§€
- **ì œì¡°Â·ì‚°ì—…:** ë¶ˆëŸ‰ ê°ì§€, ì„¤ë¹„ ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜
- **ììœ¨ì£¼í–‰:** ì°¨ëŸ‰ íƒ‘ì¬ ì„¼ì„œì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ë³„ë¡œ íŠ¹í™”ëœ í•™ìŠµ

### ğŸ”Ÿ ì°¸ê³ ìë£Œ (ì¶”ì²œ ë§í¬ ë° ë…¼ë¬¸)

- "Transfer Learning â€” Deep Learning Glossary", DeepAI.
- "A comprehensive introduction to transfer learning", Towards Data Science.
- "Transfer Learning in NLP", Google Developers.
- Papers with Code: Transfer Learning ë¶„ì•¼ ìµœì‹  ì½”ë“œÂ·ë…¼ë¬¸
- "A Survey on Transfer Learning": ì „ì´í•™ìŠµ ìµœì‹  ë™í–¥/ë¦¬ë·°ë…¼ë¬¸



