# ✅ 전이학습이란?
- **전이학습**(Transfer Learning)은 한 문제(domain)에서 학습한 모델의 지식이나 파라미터를 다른 문제로 전이하여 사용하는 머신러닝 기법입니다.
- 기존의 딥러닝은 대규모 데이터와 연산을 필요로 하지만, 전이학습을 이용하면 **적은 데이터로도 효과적으로 모델 성능을 높일** 수 있습니다.

<img width="793" height="790" alt="image" src="https://github.com/user-attachments/assets/95e451c1-63d8-4857-aaea-c285fc9c79a5" />


### 1️⃣ 전이학습의 주요 개념

- **소스 도메인(Source Domain)**: 기존에 학습이 이루어졌던 데이터와 과제
- **타깃 도메인(Target Domain)**: 지식을 이전받아 적용할 새로운 데이터와 과제
- **파인튜닝(Fine-tuning)**: 기존 모델의 일부 혹은 전체 파라미터를 새로운 데이터에 맞게 조금씩 조정하는 과정
- **Feature Extraction**: 사전 학습된 모델에서 특징만 추출하여 새로운 문제에 사용

### 2️⃣ 전이학습의 방식

| 방식            | 설명                                                                      |
|-----------------|---------------------------------------------------------------------------|
| Feature-based   | 기존 모델의 feature extractor만 사용, 마지막 분류기 부분만 새로 학습          |
| Fine-tuning     | 전체 또는 일부 레이어를 타깃 도메인 데이터로 추가 학습                      |
| Multi-task      | 여러 작업을 동시에 학습하며, 공유된 지식을 서로 다른 작업에 활용               |
| Zero-shot/One-shot | 소량 또는 전혀 없는 레이블 데이터로 타깃 도메인을 처리                     |

### 3️⃣ 전이학습의 대표적 활용 예시

- **컴퓨터 비전**: ImageNet 등 대규모 이미지 데이터로 사전 학습된 CNN 모델을, 도메인 특화 데이터(예: 의료 이미지)에 파인튜닝
- **자연어 처리**: BERT, GPT 등 대규모 텍스트 데이터에서 사전 학습된 언어모델을, 질의응답 또는 감정분석 등 특정 작업에 적용
- **음성 인식**: 대규모 음성 데이터로 학습된 모델을 개별 사용자 음성 인식에 적용

### 전이 학습을 위한 사전 훈련된 모델

- 전이 학습의 중심에는 딥러닝 연구자들이 수백만 개의 샘플 데이터 점으로 훈련시킨 사전 훈련된 딥러닝 모델이 있습니다.
- 많은 사전 훈련된 모델이 존재하며 각각의 모델에는 고려해야 할 다음과 같은 장단점이 있습니다.
- - **예측 속도: 모델이 얼마나 빠르게 새 입력을 예측할 수 있는가?** 예측 속도는 하드웨어 및 배치 크기와 같은 인자에 따라 달라질 수 있지만, 모델의 아키텍처와 크기에 따라 달라질 수도 있습니다.
- - **크기: 모델에 필요한 메모리 사용량이 어느 정도인가?** 모델 크기의 중요성은 모델을 어디로 그리고 어떻게 배포하려는지에 따라 달라집니다. 예로 모델을 임베디드 하드웨어 또는 데스크탑에서 실행할 것인지에 따라 달라질 수 있습니다. 리소스가 제약된 타겟에 배포하는 경우에는 신경망의 크기가 중요합니다.
- - **정확도: 재훈련하기 전의 모델의 성능이 얼마나 좋은가?** ImageNet 데이터셋에 대해 좋은 성능을 보이는 모델은 새로운 유사 작업에서도 좋은 성능을 보일 가능성이 높습니다. 그러나 ImageNet에서 정확도 점수가 낮다고 해서 모델이 모든 작업에서 성능이 떨어지는 것은 아닙니다.
 
<img width="1128" height="732" alt="image" src="https://github.com/user-attachments/assets/639df41d-e1c0-4c59-9c70-0ebd5ee75d37" />


### 4️⃣ 전이학습의 장점과 한계

- **장점**
  - 적은 데이터로도 좋은 성능
  - 학습 시간 및 리소스 절감
  - 소규모 데이터셋에 강점

- **한계**
  - 소스와 타깃 도메인 사이 차이가 크면 효과↓
  - 비정상적인 전이(negative transfer) 가능성
  - 하이퍼파라미터 튜닝의 어려움

### 5️⃣ 전이학습의 대표 모델

- **비전**: ResNet, VGG, Inception 등
- **자연어 처리**: BERT, GPT, RoBERTa, T5 등

### 6️⃣ 전이학습의 실습 예시 (PyTorch 기준)

```
python
import torch
import torchvision.models as models

# 사전 학습된 모델 로드
model = models.resnet50(pretrained=True)

# 마지막 분류 레이어 교체 (예: 클래스 2개인 경우)
import torch.nn as nn
model.fc = nn.Linear(model.fc.in_features, 2)

# 파인튜닝
for param in model.parameters():
    param.requires_grad = False  # feature extraction
for param in model.fc.parameters():
    param.requires_grad = True

# 이후 학습 루프 및 옵티마이저 설정
```

### 7️⃣ 대표 프레임워크 & 실전 코드

- **PyTorch**
```
python
import torch
import torchvision.models as models
import torch.nn as nn

model = models.resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # 분류기 교체

for param in model.parameters():
    param.requires_grad = False  # Feature extraction
for param in model.fc.parameters():
    param.requires_grad = True   # Classifier만 학습
```

- **TensorFlow/Keras**
  
```
python
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))
base_model.trainable = False  # Feature extractor만 사용

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(2, activation='softmax')
])
```
---

## ✏️ 사전 학습된 ConvNet을 이용한 전이 학습
### 데이터 전처리
#### 데이터 다운로드
- 이 튜토리얼에서는 수천 개의 고양이와 개의 이미지가 포함된 데이터세트를 사용합니다.
- 이미지가 포함된 zip 파일을 다운로드하여 추출은 다음 `tf.keras.utils.image_dataset_from_directory` 유틸리티를 사용하여 훈련 및 검증을 위한 `tf.data.Dataset`를 생성합니다.
```
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                            shuffle=True,
                                                            batch_size=BATCH_SIZE,
                                                            image_size=IMG_SIZE)
```

```
validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,
                                                                 shuffle=True,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE)
```
- 훈련용 데이터셋에서 처음 두 개의 이미지 및 레이블을 보여줍니다:
```
class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```
<img width="793" height="812" alt="image" src="https://github.com/user-attachments/assets/eed17668-b450-49b8-b126-261c3c624ec1" />

- 원본 데이터세트에는 테스트 세트가 포함되어 있지 않으므로 테스트 세트를 생성합니다.
- `tf.data.experimental.cardinality`를 사용하여 검증 세트에서 사용할 수 있는 데이터 배치 수를 확인한 다음 그 중 20%를 테스트 세트로 이동합니다.
```
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))
print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))
```

#### 성능을 높이도록 데이터세트 구성하기
- 버퍼링된 프리페치를 사용하여 I/O 차단 없이 디스크에서 이미지를 로드합니다.
```
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```
#### 데이터 증강 사용
- 큰 이미지 데이터세트가 없는 경우, 회전 및 수평 뒤집기와 같이 훈련 이미지에 무작위이지만 사실적인 변환을 적용하여 샘플 다양성을 인위적으로 도입하는 것이 좋습니다.
- 이것은 모델을 훈련 데이터의 다양한 측면에 노출시키고 과대적합을 줄이는 데 도움이 됩니다.

```
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('horizontal'),
  tf.keras.layers.RandomRotation(0.2),
])
```
- 참고: `model.fit`을 호출할 때 훈련 중에만 이러한 레이어가 활성화됩니다.
- `model.evaulate` 또는 `model.fit`의 추론 모드에서 모델을 사용하면 비활성화됩니다.
- 같은 이미지에 이 레이어를 반복해서 적용하고 결과를 확인해 보겠습니다.
```
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```

<img width="793" height="790" alt="image" src="https://github.com/user-attachments/assets/3e55046b-05b6-4700-b9ae-cfd83c18adea" />


---

### 8️⃣ 전이학습의 최신 트렌드 및 고급 기법

- **도메인 적응(Domain Adaptation):** 데이터 분포가 다른 소스와 타깃 사이 격차를 줄이는 기술
- **멀티태스크 러닝(Multi-task Learning):** 여러 작업에서 공통 특성 추출해 일반화 능력 강화
- **제로샷/퓨샷 러닝:** 데이터 부족 상황에서의 일반화(대규모 언어 모델 등)
- **연속적 학습(Lifelong/Continual Learning):** 여러 작업을 순차적으로 학습하면서 과거 경험을 보존하는 연구
- **페더레이티드 러닝:** 여러 데이터 소스를 분산형으로 학습, 데이터 프라이버시와 안전 고려


### 9️⃣ 전이학습 산업 응용사례

- **의료:** 암 진단, 병변 탐지 등 의료 이미지 분석
- **금융:** 신용평가, 사기 탐지
- **제조·산업:** 불량 감지, 설비 예측 유지보수
- **자율주행:** 차량 탑재 센서에서 수집된 데이터별로 특화된 학습

### 🔟 참고자료 (추천 링크 및 논문)

- "Transfer Learning — Deep Learning Glossary", DeepAI.
- "A comprehensive introduction to transfer learning", Towards Data Science.
- "Transfer Learning in NLP", Google Developers.
- Papers with Code: Transfer Learning 분야 최신 코드·논문
- "A Survey on Transfer Learning": 전이학습 최신 동향/리뷰논문



